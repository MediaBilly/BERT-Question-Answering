{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"nq_to_squad.ipynb","provenance":[],"authorship_tag":"ABX9TyN9sjQYOJtj4JSrUJLWsBZw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Download full NQ dataset**"],"metadata":{"id":"Uz5n62EhSf1i"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"68fHzvBrL-ml","executionInfo":{"status":"ok","timestamp":1646605085722,"user_tz":-120,"elapsed":423696,"user":{"displayName":"Βασίλης Κυριακόπουλος","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLJ843-mdA-XYMgrr2K7G5eg-3pPcT6fAhtDjZiw=s64","userId":"10189451843812858163"}},"outputId":"81128e54-522c-4b4f-ec1e-7ca5e6332b90"},"outputs":[{"output_type":"stream","name":"stdout","text":["Copying gs://natural_questions/v1.0/LICENSE.txt...\n","/ [0/62 files][    0.0 B/ 42.0 GiB]   0% Done                                   \rCopying gs://natural_questions/v1.0/README.txt...\n","/ [0/62 files][    0.0 B/ 42.0 GiB]   0% Done                                   \rCopying gs://natural_questions/v1.0/dev/nq-dev-00.jsonl.gz...\n","/ [0/62 files][    0.0 B/ 42.0 GiB]   0% Done                                   \rCopying gs://natural_questions/v1.0/dev/nq-dev-02.jsonl.gz...\n","Copying gs://natural_questions/v1.0/dev/nq-dev-03.jsonl.gz...\n","/ [0/62 files][    0.0 B/ 42.0 GiB]   0% Done                                   \r/ [0/62 files][    0.0 B/ 42.0 GiB]   0% Done                                   \rCopying gs://natural_questions/v1.0/dev/nq-dev-01.jsonl.gz...\n","/ [0/62 files][    0.0 B/ 42.0 GiB]   0% Done                                   \rCopying gs://natural_questions/v1.0/dev/nq-dev-04.jsonl.gz...\n","/ [0/62 files][    0.0 B/ 42.0 GiB]   0% Done                                   \rCopying gs://natural_questions/v1.0/sample/nq-train-sample.jsonl.gz...\n","Copying gs://natural_questions/v1.0/sample/nq-dev-sample.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-00.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-01.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-02.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-04.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-03.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-05.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-06.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-07.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-08.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-09.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-10.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-11.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-12.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-13.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-14.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-15.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-16.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-17.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-18.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-19.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-20.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-21.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-22.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-23.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-24.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-25.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-26.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-27.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-28.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-29.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-30.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-31.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-32.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-33.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-34.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-35.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-36.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-37.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-38.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-39.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-40.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-41.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-42.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-43.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-44.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-45.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-46.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-47.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-48.jsonl.gz...\n","Copying gs://natural_questions/v1.0/train/nq-train-49.jsonl.gz...\n"]}],"source":["!gsutil -m cp -R gs://natural_questions/v1.0 ."]},{"cell_type":"markdown","source":["**Initialize nq_to_squad.py script**"],"metadata":{"id":"YtN0Dpx2UHyT"}},{"cell_type":"code","source":["# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\").\n","# You may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# http://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License.\n","\n","\n","# We include functions that are copied/modified from\n","# https://github.com/google-research-datasets/natural-questions/blob/master/nq_browser.py\n","# cite: https://github.com/google-research-datasets/natural-questions/\n","\n","import json\n","import argparse\n","import gzip\n","import glob\n","import numpy as np\n","from bs4 import BeautifulSoup\n","\n","\n","def has_long_answer(nq_example):\n","    if len(nq_example['annotations']) == 1:\n","        annotation = nq_example['annotations'][0]\n","        return annotation['long_answer']['start_byte'] >= 0\n","    else:\n","        return sum([annotation['long_answer']['start_byte'] >= 0 for annotation in nq_example['annotations']]) >= 2\n","\n","\n","def has_short_answer(nq_example):\n","    if len(nq_example['annotations']) == 1:\n","        annotation = nq_example['annotations'][0]\n","        return annotation['short_answers'] or annotation['yes_no_answer'] != 'NONE'\n","    else:\n","        return sum([bool(annotation['short_answers']) or annotation['yes_no_answer'] != 'NONE'\n","                    for annotation in nq_example['annotations']]) >= 2\n","\n","\n","def render_answer(nq_example, start_byte, end_byte):\n","    html = nq_example['document_html'].encode('utf-8')\n","    answer_text = BeautifulSoup(html[start_byte:end_byte].decode('utf-8'), features='lxml').get_text()\n","    return answer_text\n","\n","\n","def get_long_answer(nq_example):\n","    if has_long_answer(nq_example):\n","        long_answers = [a['long_answer'] for a in nq_example['annotations'] if a['long_answer']['start_byte'] >= 0]\n","        long_answer_bounds = [(la['start_byte'], la['end_byte']) for la in long_answers]\n","        long_answer_counts = [long_answer_bounds.count(la) for la in long_answer_bounds]\n","        long_answer = long_answers[np.argmax(long_answer_counts)]\n","        html_tag = nq_example['document_tokens'][long_answer['end_token'] - 1]['token']\n","        if html_tag == '</P>':\n","            long_answer_text = render_answer(nq_example, long_answer['start_byte'], long_answer['end_byte'])\n","            return long_answer_text\n","    return None\n","\n","\n","def get_short_answers(nq_example):\n","    if has_short_answer(nq_example):\n","        short_answers = [a['short_answers'] for a in nq_example['annotations'] if a['short_answers']]\n","        short_answers_texts = [\n","            ', '.join([render_answer(nq_example, s['start_byte'], s['end_byte']) for s in short_answer])\n","            for short_answer in short_answers]\n","        short_answers_texts = set(short_answers_texts)\n","        return short_answers_texts\n","    return None\n","\n","\n","def nq_to_squad_format(nq_dir, output_file):\n","    data = []\n","    for filename in glob.glob(nq_dir + '/*.gz'):\n","        with gzip.open(filename, 'r') as f:\n","            for line in f:\n","                nq_example = json.loads(line)\n","                long_answer_text = get_long_answer(nq_example)\n","\n","                if long_answer_text:\n","                    question_text = nq_example['question_text']\n","                    context = long_answer_text\n","                    para = {'context': context, 'qas': [{'question': question_text, 'answers': []}]}\n","                    data.append({'paragraphs': [para]})\n","                    qa = para['qas'][0]\n","                    qa['id'] = str(nq_example['example_id'])\n","                    qa['is_impossible'] = True\n","                    short_answer_texts = get_short_answers(nq_example)\n","\n","                    if short_answer_texts:\n","                        for ans_string in short_answer_texts:\n","                            index = context.find(ans_string)\n","                            if index != -1:\n","                                qa['answers'].append({'text': ans_string, 'answer_start': index})\n","                                qa['is_impossible'] = False\n","\n","    nq_as_squad = {'data': data, 'version': '2.0'}\n","\n","    with open(output_file, 'w', encoding='utf-8') as outfile:\n","        outfile.write(json.dumps(nq_as_squad, indent=2, sort_keys=True, ensure_ascii=False))"],"metadata":{"id":"NYJ7XJGyUIzq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Convertion Time!!!**"],"metadata":{"id":"cZfyj8o_UWf7"}},{"cell_type":"code","source":["nq_to_squad_format(nq_dir=\"v1.0/train\", output_file=\"nq_train.json\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A7FISEuwVMEG","executionInfo":{"status":"ok","timestamp":1646612605861,"user_tz":-120,"elapsed":6953760,"user":{"displayName":"Βασίλης Κυριακόπουλος","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLJ843-mdA-XYMgrr2K7G5eg-3pPcT6fAhtDjZiw=s64","userId":"10189451843812858163"}},"outputId":"c9e09bf5-2700-43f4-e78b-9e7df307441d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/bs4/__init__.py:336: UserWarning: \"http://www.example.com/index.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n","  ' that document to Beautiful Soup.' % decoded_markup\n"]}]},{"cell_type":"code","source":["nq_to_squad_format(nq_dir=\"v1.0/dev\", output_file=\"nq_dev.json\")"],"metadata":{"id":"onT4GYkBUVG5"},"execution_count":null,"outputs":[]}]}